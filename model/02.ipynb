{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 고객의 채무 불이행 여부 분류\n",
    "---\n",
    "#### 데이터 양\n",
    "- train : 100,000 개\n",
    "- test : 35,815 개\n",
    "---\n",
    "#### input과 output\n",
    "- input : 고객 재무 상태에 대한 75개 feature\n",
    "- output : 채무 불이행 여부\n",
    "    - 0 = 이행\n",
    "    - 1 = 불이행 / 부도\n",
    "---\n",
    "#### features\n",
    "- **int_rate** : 대출자에 부여된 이자율 (Interest rate of the loan the applicant received)\n",
    "- **annual_inc** : 연 소득 (annual income)\n",
    "- **dti** : 소득 대비 부채 비율 (Debt-to-income ratio)\n",
    "- **delinq_2yrs** : 지난 2년 간 체납 발생 횟수 (Delinquencies on lines of credit in the last 2 years)\n",
    "- **inq_last_6mths** : 지난 6개월 간 신용 조회 수 (Inquiries into the applicant's credit during the last 6 months)\n",
    "- **pub_rec** : 파산 횟수 (Number of bankruptcies listed in the public record)\n",
    "- **revol_bal** : 리볼빙 잔액 (Total credit revolving balance)\n",
    "- **total_acc** : 지금까지 소유했던 신용카드 개수 (num_total_cc_accounts : Total number of credit card accounts in the applicant's history)\n",
    "- **collections_12_mths_ex_med** : 의료부문을 제외한 지난 12개월 간 추심 발생 횟수 (num_collections_last_12m : Number of collections in the last 12 months. This excludes medical collections)\n",
    "- **acc_now_delinq** : 대출자가 체납 상태에 있지 않은 계좌의 수 (The number of accounts on which the borrower is now delinquent)\n",
    "- **tot_coll_amt** : 대출자에 대한 현재까지의 총 추심액 (total_collection_amount_ever : The total amount that the applicant has had against them in collections)\n",
    "- **tot_cur_bal** : 전 계좌의 현재 통합 잔고 (Total current balance of all accounts)\n",
    "- **chargeoff_within_12_mths** : 대출 부 신청인의 대출 신청 직전 12개월 간 세금 공제 횟수 (Number of charge-offs within last 12 months at time of application for the secondary applicant)\n",
    "- **delinq_amnt** : 체납 금액 (delinquency amount)\n",
    "- **tax_liens** : 세금 저당권의 수 (Number of tax liens)\n",
    "- **emp_length1** ~ 12 : 고용 연수 (Number of years in the job)\n",
    "- **home_ownership1** ~ 6 : 대출 신청자의 주거 소유 형태 (The ownership status of the applicant's residence)\n",
    "- **verification_status1** ~ 3 : 공동 소득 발생 여부 및 형태 (verification_income_joint : Type of verification of the joint income)\n",
    "- **purpose1** ~ 14 : 대출 목적 (The purpose of the loan)\n",
    "- **initial_list_status1** ~ 2 : 최초 대출 상태 (Initial listing status of the loan)\n",
    "- **mths_since_last_delinq1** ~ 11 : 마지막 체납이 지금으로부터 몇개월 전에 있었는지를 나타내는 변수 (Months since the last delinquency)\n",
    "- **funded_amnt** : 대출액 (Funded amount)\n",
    "- **funded_amnt_inv** : 사채 대출액 (Funded amount by investors)\n",
    "- **total_rec_late_fee** : 총 연체료 중 납부액 (Late fees received to date)\n",
    "- **term1** : 상환 기간 (The number of payments on the loan. Values are in months and can be either 36 or 60)\n",
    "- **open_acc** : 개설 개좌 수 (The number of open credit lines in the borrower's credit file)\n",
    "- **installment** : 대출 발생 시 월 상환액 (The monthly payment owed by the borrower if the loan originates)\n",
    "- **revol_util** : 리볼빙 한도 대비 리볼빙 사용 비율 (Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit)\n",
    "- **out_prncp** : 대출액 중 원리금 잔액 (Remaining outstanding principal for total amount funded)\n",
    "- **out_prncp_inv** : 사채 대출액 중 원리금 잔액 (Remaining outstanding principal for total amount funded by investors)\n",
    "- **total_rec_int** : 이자 상환액 (Interest received to date)\n",
    "- **fico_range_low** : FICO(일종의 신용점수) 최저값 (The lower boundary range the borrowerʼs FICO at loan origination belongs to)\n",
    "- **fico_range_high** : FICO(일종의 신용점수) 최고값 (The upper boundary range the borrowerʼs FICO at loan origination belongs to)\n",
    "- **depvar** : 고객의 부도 여부 (dependent variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 필요 데이터 로드\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Libraries for machin learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['int_rate', 'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths',\n",
       "       'pub_rec', 'revol_bal', 'total_acc', 'collections_12_mths_ex_med',\n",
       "       'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal',\n",
       "       'chargeoff_within_12_mths', 'delinq_amnt', 'tax_liens', 'emp_length1',\n",
       "       'emp_length2', 'emp_length3', 'emp_length4', 'emp_length5',\n",
       "       'emp_length6', 'emp_length7', 'emp_length8', 'emp_length9',\n",
       "       'emp_length10', 'emp_length11', 'emp_length12', 'home_ownership1',\n",
       "       'home_ownership2', 'home_ownership3', 'home_ownership4',\n",
       "       'home_ownership5', 'home_ownership6', 'verification_status1',\n",
       "       'verification_status2', 'verification_status3', 'purpose1', 'purpose2',\n",
       "       'purpose3', 'purpose4', 'purpose5', 'purpose6', 'purpose7', 'purpose8',\n",
       "       'purpose9', 'purpose10', 'purpose11', 'purpose12', 'purpose13',\n",
       "       'purpose14', 'initial_list_status1', 'initial_list_status2',\n",
       "       'mths_since_last_delinq1', 'mths_since_last_delinq2',\n",
       "       'mths_since_last_delinq3', 'mths_since_last_delinq4',\n",
       "       'mths_since_last_delinq5', 'mths_since_last_delinq6',\n",
       "       'mths_since_last_delinq7', 'mths_since_last_delinq8',\n",
       "       'mths_since_last_delinq9', 'mths_since_last_delinq10',\n",
       "       'mths_since_last_delinq11', 'funded_amnt', 'funded_amnt_inv',\n",
       "       'total_rec_late_fee', 'term1', 'open_acc', 'installment', 'revol_util',\n",
       "       'out_prncp', 'out_prncp_inv', 'total_rec_int', 'fico_range_low',\n",
       "       'fico_range_high'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:, :-1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       int_rate  annual_inc  dti  delinq_2yrs  inq_last_6mths  pub_rec  \\\n",
      "0          -1.0        -1.0  1.0         -0.0             0.0     -0.0   \n",
      "1          -0.0         0.0 -2.0         -0.0             0.0      1.0   \n",
      "2          -0.0        -0.0  1.0         -0.0             2.0     -0.0   \n",
      "3           0.0         0.0 -0.0          4.0             1.0     -0.0   \n",
      "4          -0.0        -1.0  1.0         -0.0             0.0      3.0   \n",
      "...         ...         ...  ...          ...             ...      ...   \n",
      "99995       1.0        -0.0 -0.0         -0.0             2.0      1.0   \n",
      "99996      -1.0        -0.0 -2.0         -0.0            -1.0     -0.0   \n",
      "99997       0.0        -0.0  2.0         -0.0             0.0     -0.0   \n",
      "99998       2.0        -1.0 -2.0         -0.0             0.0     -0.0   \n",
      "99999       1.0         1.0  2.0         -0.0            -1.0     -0.0   \n",
      "\n",
      "       revol_bal  total_acc  collections_12_mths_ex_med  acc_now_delinq  ...  \\\n",
      "0           -1.0        0.0                        -0.0            -0.0  ...   \n",
      "1           -0.0       -0.0                        -0.0            -0.0  ...   \n",
      "2           -0.0       -1.0                        -0.0            -0.0  ...   \n",
      "3           -0.0        0.0                        -0.0            -0.0  ...   \n",
      "4           -0.0       -1.0                        -0.0            -0.0  ...   \n",
      "...          ...        ...                         ...             ...  ...   \n",
      "99995       -0.0       -0.0                         7.0            -0.0  ...   \n",
      "99996       -1.0       -1.0                        -0.0            -0.0  ...   \n",
      "99997       -0.0       -0.0                        -0.0            -0.0  ...   \n",
      "99998       -1.0       -2.0                        -0.0            -0.0  ...   \n",
      "99999        1.0        0.0                        -0.0            -0.0  ...   \n",
      "\n",
      "       total_rec_late_fee  term1  open_acc  installment  revol_util  \\\n",
      "0                    -0.0    0.0       1.0         -1.0        -2.0   \n",
      "1                    -0.0    0.0      -1.0         -1.0        -0.0   \n",
      "2                    -0.0    0.0      -1.0         -1.0         1.0   \n",
      "3                    -0.0    0.0       0.0          0.0        -0.0   \n",
      "4                    -0.0    0.0      -1.0         -0.0        -1.0   \n",
      "...                   ...    ...       ...          ...         ...   \n",
      "99995                -0.0    0.0       0.0          1.0         1.0   \n",
      "99996                -0.0    0.0      -1.0         -1.0        -2.0   \n",
      "99997                -0.0    0.0       1.0         -1.0         0.0   \n",
      "99998                -0.0    0.0      -2.0         -1.0         1.0   \n",
      "99999                -0.0    0.0       1.0          3.0        -0.0   \n",
      "\n",
      "       out_prncp  out_prncp_inv  total_rec_int  fico_range_low  \\\n",
      "0           -0.0           -0.0           -1.0             2.0   \n",
      "1           -0.0           -0.0           -0.0            -1.0   \n",
      "2           -0.0           -0.0           -1.0            -1.0   \n",
      "3           -0.0           -0.0           -0.0            -0.0   \n",
      "4           -0.0           -0.0           -1.0            -1.0   \n",
      "...          ...            ...            ...             ...   \n",
      "99995       -0.0           -0.0            1.0            -1.0   \n",
      "99996       -0.0           -0.0           -1.0             2.0   \n",
      "99997       -0.0           -0.0           -0.0            -1.0   \n",
      "99998       -0.0           -0.0           -0.0             1.0   \n",
      "99999       -0.0           -0.0            2.0            -0.0   \n",
      "\n",
      "       fico_range_high  \n",
      "0                  2.0  \n",
      "1                 -1.0  \n",
      "2                 -1.0  \n",
      "3                 -0.0  \n",
      "4                 -1.0  \n",
      "...                ...  \n",
      "99995             -1.0  \n",
      "99996              2.0  \n",
      "99997             -1.0  \n",
      "99998              1.0  \n",
      "99999             -0.0  \n",
      "\n",
      "[100000 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "# StandardSclaer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale_data = train.iloc[:, :-1]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(scale_data)\n",
    "scaler_data_scaled = scaler.transform(scale_data)\n",
    "scaler_data_scaled = pd.DataFrame(scaler_data_scaled)\n",
    "scaler_data_scaled.columns = scale_data.columns\n",
    "scaler_data_scaled = round(scaler_data_scaled)\n",
    "print(scaler_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IsolationForest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import collections\n",
    "\n",
    "clf = IsolationForest(\n",
    "                    n_estimators=100,\n",
    "                    max_samples=\"auto\", \n",
    "                    contamination=0.1,\n",
    "                    max_features=1,\n",
    "                    bootstrap=False,\n",
    "                    n_jobs=1,\n",
    "                    random_state=42,\n",
    "                    verbose=0\n",
    ")\n",
    "\n",
    "# fit 함수를 이용하여, 데이터셋을 학습시킨다.\n",
    "clf.fit(scaler_data_scaled)\n",
    "\n",
    "# predict 함수를 이용하여, outlier를 판별해 준다. 0과 1로 이루어진 Series형태의 데이터가 나온다.\n",
    "y_pred_outliers = clf.predict(scaler_data_scaled)\n",
    "collections.Counter(y_pred_outliers)\n",
    "\n",
    "\n",
    "scaler_data_scaled['out'] = y_pred_outliers\n",
    "outliers = scaler_data_scaled.loc[scaler_data_scaled['out'] == -1]\n",
    "outlier_index = list(outliers.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. PCA(component = 3), Scaler와 무관하게 코드 동일\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "def scaled_pca(X_scaled):\n",
    "    pca = PCA(n_components=3)\n",
    "    X_scaled_reduce = pca.fit_transform(X_scaled)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_zlabel(\"x_composite_3\")\n",
    "    # Plot the compressed data points\n",
    "    ax.scatter(X_scaled_reduce[:, 0], X_scaled_reduce[:, 1], zs=X_scaled_reduce[:, 2], s=4, lw=4, label=\"inliers\",c=\"green\")\n",
    "    # Plot x's for the ground truth outliers\n",
    "    ax.scatter(X_scaled_reduce[outlier_index,0],X_scaled_reduce[outlier_index,1], \n",
    "            X_scaled_reduce[outlier_index,2],\n",
    "            lw=2, s=60, marker=\"x\", c=\"red\", label=\"outliers\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 4. PCA(component = 2), Scaler와 무관하게 코드 동일\n",
    "\n",
    "    pca = PCA(2)\n",
    "    pca.fit(X_scaled)\n",
    "    res=pd.DataFrame(pca.transform(X_scaled))\n",
    "    Z = np.array(res)\n",
    "    plt.title(\"IsolationForest\")\n",
    "    b1 = plt.scatter(res[0], res[1], c='green',\n",
    "                    s=20,label=\"normal points\")\n",
    "    b1 =plt.scatter(res.iloc[outlier_index,0],res.iloc[outlier_index,1], c='green',s=20,  edgecolor=\"red\",label=\"predicted outliers\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 77)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_data_scaled['depvar'] = train['depvar']\n",
    "scale_data = scaler_data_scaled.loc[scaler_data_scaled['out'] == 1]\n",
    "scale_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 75) (90000,)\n"
     ]
    }
   ],
   "source": [
    "X = scale_data.drop(['depvar', 'out'], axis=1)\n",
    "y = scale_data['depvar']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# print(f'train shape : {X_train.shape}, {y_train.shape}')\n",
    "# print(f'train shape : {X_val.shape}, {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val.sum()/len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 채점\n",
    "def get_clf_eval(y_answer, y_pred):\n",
    "    acc = metrics.accuracy_score(y_answer, y_pred)\n",
    "    prec = metrics.precision_score(y_answer, y_pred)\n",
    "    recall = metrics.recall_score(y_answer, y_pred)\n",
    "    AUC = metrics.roc_auc_score(y_answer, y_pred)\n",
    "    F1 = metrics.f1_score(y_answer, y_pred, average=\"macro\")\n",
    "    confus_met = metrics.confusion_matrix(y_answer, y_pred)\n",
    "\n",
    "    print(\"========================\")\n",
    "    print(\"정확도 : {:.6f}\".format(acc))\n",
    "    print(\"정밀도 : {:.6f}\".format(prec))\n",
    "    print(\"재현율 : {:.6f}\".format(recall))\n",
    "    print(\"AUC : {:.6f}\".format(AUC))\n",
    "    \n",
    "    print(\" ** F1 : {:.6f} **\".format(F1))\n",
    "    \n",
    "    print(\"====confusion_matrix====\\n{}\".format(confus_met))\n",
    "    print(\"========================\")\n",
    "\n",
    "    return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m fold_scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m models \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, val_index \u001b[38;5;129;01min\u001b[39;00m skf\u001b[38;5;241m.\u001b[39msplit(\u001b[43mX\u001b[49m, y):\n\u001b[1;32m     11\u001b[0m     X_train, X_val \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc[train_index], X\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[1;32m     12\u001b[0m     y_train, y_val \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[val_index]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "model = XGBClassifier()\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_scores = []\n",
    "models = []\n",
    "\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    score = get_clf_eval(y_val, y_pred)\n",
    "    fold_scores.append(score)\n",
    "    models.append(model)\n",
    "\n",
    "best_fold_index = fold_scores.index(max(fold_scores))\n",
    "best_model = models[best_fold_index]\n",
    "\n",
    "print(f\"Best fold: {best_fold_index}\")\n",
    "print(f\"Best fold score: {fold_scores[best_fold_index]}\")\n",
    "print(f\"Mean accuracy: {sum(fold_scores) / len(fold_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35816, 75)\n"
     ]
    }
   ],
   "source": [
    "X_test = test.iloc[:, 1:]\n",
    "transformed_X_test = scaler.transform(X_test)\n",
    "transformed_X_test = pd.DataFrame(transformed_X_test)\n",
    "transformed_X_test.columns = X_test.columns\n",
    "transformed_X_test = round(transformed_X_test)\n",
    "print(transformed_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = best_model.predict(transformed_X_test)\n",
    "\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['answer'] = test_pred\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yeardream",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
